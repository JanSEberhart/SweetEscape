# SweetEscape ğŸ¬

SweetEscape ist ein Machine-Learning-Projekt zur Klassifikation des Diabetes-Risikos  
(**kein Diabetes**, **PrÃ¤diabetes**, **Diabetes**) auf Basis von Gesundheits- und
Lebensstilmerkmalen aus dem BRFSS-2015-Datensatz.

Ziel ist der Aufbau einer **nachvollziehbaren und reproduzierbaren ML-Pipeline**  
(Daten â†’ Feature Engineering â†’ Modellvergleich â†’ finales Modell â†’ Web-App).

---

## Projektstruktur

- `data/raw/` â€“ originale Rohdaten (unverÃ¤ndert)
- `data/processed/` â€“ verarbeitete Daten (Output aus Feature Engineering)
- `notebooks/` â€“ vollstÃ¤ndiger, nachvollziehbarer Workflow
  - `00_preprocessing_feature_engineering.ipynb`  
    â†’ Preprocessing & Feature Engineering, erzeugt `diabetes_fe.csv`
  - `01_train_model.ipynb`  
    â†’ Modelltraining, Vergleich mehrerer Modelle, Auswahl & Speicherung des finalen Modells
- `models/` â€“ gespeichertes finales Modell (`diabetes_final_model.joblib`)
- `src/` â€“ wiederverwendbarer Projektcode (z. B. Hilfsfunktionen, Konstanten)
- `app.py` â€“ Streamlit-Webanwendung (lokal ausfÃ¼hrbar)
- `requirements.txt` â€“ benÃ¶tigte Python-AbhÃ¤ngigkeiten

**Warum diese Struktur?**  
Sie trennt Rohdaten, Verarbeitung, Training und Deployment sauber und macht das Projekt
reproduzierbar, wartbar und prÃ¼fbar.

---

## Workflow (Reproduzierbarkeit)

1. **Rohdaten** liegen in `data/raw/diabetes_raw.csv`
2. Notebook **00_preprocessing_feature_engineering.ipynb** ausfÃ¼hren  
   â†’ erzeugt `data/processed/diabetes_fe.csv`
3. Notebook **01_train_model.ipynb** ausfÃ¼hren  
   â†’ trainiert und vergleicht mehrere Modelle  
   â†’ speichert das **finale Modell** als `models/diabetes_final_model.joblib`
4. `app.py` lokal starten  
   â†’ lÃ¤dt das gespeicherte Modell und fÃ¼hrt Vorhersagen fÃ¼r Nutzereingaben aus

---

## Feature Engineering (Notebook 00)

Der Datensatz ist bereits stark vorverarbeitet (viele binÃ¤re Indikatoren und
kategoriale Codes).  
Daher wird bewusst **nur moderates Feature Engineering** durchgefÃ¼hrt, um die
Interpretierbarkeit der Merkmale zu erhalten.

Beispiele fÃ¼r abgeleitete Features:
- `inactive` â€“ abgeleitet aus fehlender kÃ¶rperlicher AktivitÃ¤t
- `cardio_risk_sum` â€“ Summenfeature aus kardiovaskulÃ¤ren Risikofaktoren
- `lifestyle_risk_sum` â€“ Summenfeature aus Lifestyle-Risiken
- `poor_health` â€“ binÃ¤r abgeleitet aus `GenHlth`
- `mental_physical_burden` â€“ Kombination aus mentalen und kÃ¶rperlichen Belastungstagen

Output:
- `data/processed/diabetes_fe.csv`

---

## Modelltraining & Vergleich (Notebook 01)

Es werden **drei Modelle** unter identischen Bedingungen trainiert und verglichen
(gleicher Train/Test-Split, gleiche Metriken):

1. **Logistic Regression** (`class_weight="balanced"`)  
   â†’ interpretierbare Baseline
2. **Random Forest** (`class_weight="balanced_subsample"`)  
   â†’ nicht-lineares Vergleichsmodell
3. **HistGradientBoosting** (mit `sample_weight`)  
   â†’ Boosting-Ansatz fÃ¼r tabellarische Daten

### Warum Macro-F1 als Hauptmetrik?

Der Datensatz ist stark unausgeglichen:
- viele FÃ¤lle **kein Diabetes**
- sehr wenige FÃ¤lle **PrÃ¤diabetes**

Eine hohe Accuracy wÃ¤re daher irrefÃ¼hrend.

**Macro-F1** mittelt den F1-Score **Ã¼ber alle Klassen** und berÃ¼cksichtigt damit
Minderheitsklassen gleichwertig. ZusÃ¤tzlich werden:
- der **Recall** fÃ¼r PrÃ¤diabetes und Diabetes
- sowie die **Confusion Matrix**

zur Bewertung herangezogen.

### Finale Modellwahl

Basierend auf dem Vergleich wurde **Logistic Regression (balanced)** als finales Modell gewÃ¤hlt,
da es:
- den hÃ¶chsten **Macro-F1-Score** erreicht
- stabile Ergebnisse fÃ¼r Minderheitsklassen liefert
- und gut interpretierbar bleibt

Gespeichert als:
- `models/diabetes_final_model.joblib`

---

## Web-App (lokal)

Die Web-Anwendung ist mit **Streamlit** umgesetzt und lÃ¤dt das gespeicherte Modell.

Funktionen der App:
- Eingabe gesundheitlicher und lebensstilbezogener Merkmale
- automatische Berechnung des BMI aus GrÃ¶ÃŸe & Gewicht
- Ausgabe einer **probabilistischen EinschÃ¤tzung** fÃ¼r alle drei Klassen

Nicht alle Angaben sind verpflichtend; **nicht ausgefÃ¼llte optionale Felder werden
neutral angenommen**.

**Hinweis:**  
Die Anwendung dient ausschlieÃŸlich zur **ersten RisikoeinschÃ¤tzung** und ersetzt
keine Ã¤rztliche Diagnose.

---

## Getting Started (lokal ausfÃ¼hren)

### Voraussetzungen
- Python **3.10 oder hÃ¶her**
- Git

### Installation & Start

```bash
git clone https://github.com/JanSEberhart/SweetEscape.git
cd SweetEscape
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
streamlit run app.py
```


## Erweiterung: BinÃ¤re Klassifikation (App 2)

ZusÃ¤tzlich zur Multiclass-Variante gibt es eine **binÃ¤re Klassifikation**:

- **0 = kein Diabetes**
- **1 = Diabetes-Risiko** (PrÃ¤diabetes **oder** Diabetes)

**Warum?**  
Die ursprÃ¼ngliche Klasse â€PrÃ¤diabetesâ€œ ist im Datensatz sehr selten und schwer abzugrenzen. Durch das Zusammenfassen zu â€Risikoâ€œ wird das Lernproblem stabiler und die Metriken (z. B. F1/ROC-AUC) werden robuster.

### Dateien
- `data/processed/diabetes_fe_binary.csv` â€“ Feature-engineerte Daten + Target `Diabetes_binary`
- `notebooks/02_train_binary_model.ipynb` â€“ Training/Evaluation der binÃ¤ren Variante
- `models/diabetes_binary_model.joblib` â€“ gespeichertes Binary-Modell
- `apps/app_binary.py` â€“ Streamlit-App fÃ¼r die binÃ¤re Vorhersage

### App starten (Binary)
Im Projekt-Root (venv aktiv):

```bash
streamlit run apps/app_binary.py
```
