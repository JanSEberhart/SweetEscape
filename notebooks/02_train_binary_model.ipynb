{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 02 – Binary Modelltraining (Diabetes-Risiko: Ja/Nein)\n",
    "\n",
    "**Ziel:** Wir trainieren ein binäres Modell, das nur zwischen **kein Diabetes** (0) und **Diabetes-Risiko** (1) unterscheidet.\n",
    "**Warum?** Die Klasse „Prädiabetes“ ist im Datensatz extrem selten und schwer abzugrenzen, daher ist ein binäres Setting oft stabiler."
   ],
   "id": "c653a97ffa931428"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1) Datenbasis\n",
    "\n",
    "Wir laden den bereits feature-engineerten **Binary-Datensatz** (`diabetes_fe_binary.csv`), damit Training und App später exakt dieselben Features verwenden."
   ],
   "id": "4d8a094eb3a09e06"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-11T15:40:15.432508700Z",
     "start_time": "2026-01-11T15:40:15.215093300Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score\n",
    "import joblib\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\")\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"diabetes_fe_binary.csv\"\n",
    "MODEL_OUT = PROJECT_ROOT / \"models\" / \"diabetes_binary_model.joblib\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  HeartDiseaseorAttack  \\\n",
       "0     1.0       1.0        1.0  40.0     1.0     0.0                   0.0   \n",
       "1     0.0       0.0        0.0  25.0     1.0     0.0                   0.0   \n",
       "2     1.0       1.0        1.0  28.0     0.0     0.0                   0.0   \n",
       "3     1.0       0.0        1.0  27.0     0.0     0.0                   0.0   \n",
       "4     1.0       1.0        1.0  24.0     0.0     0.0                   0.0   \n",
       "\n",
       "   PhysActivity  Fruits  Veggies  ...  Education  Income  inactive  \\\n",
       "0           0.0     0.0      1.0  ...        4.0     3.0         1   \n",
       "1           1.0     0.0      0.0  ...        6.0     1.0         0   \n",
       "2           0.0     1.0      0.0  ...        4.0     8.0         1   \n",
       "3           1.0     1.0      1.0  ...        3.0     6.0         0   \n",
       "4           1.0     1.0      1.0  ...        5.0     4.0         0   \n",
       "\n",
       "   cardio_risk_sum  low_fruits  low_veggies  lifestyle_risk_sum  poor_health  \\\n",
       "0              2.0           1            0                 3.0            1   \n",
       "1              0.0           1            1                 3.0            0   \n",
       "2              2.0           0            1                 2.0            1   \n",
       "3              1.0           0            0                 0.0            0   \n",
       "4              2.0           0            0                 0.0            0   \n",
       "\n",
       "   mental_physical_burden  Diabetes_binary  \n",
       "0                    33.0                0  \n",
       "1                     0.0                0  \n",
       "2                    60.0                0  \n",
       "3                     0.0                0  \n",
       "4                     3.0                0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>inactive</th>\n",
       "      <th>cardio_risk_sum</th>\n",
       "      <th>low_fruits</th>\n",
       "      <th>low_veggies</th>\n",
       "      <th>lifestyle_risk_sum</th>\n",
       "      <th>poor_health</th>\n",
       "      <th>mental_physical_burden</th>\n",
       "      <th>Diabetes_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2) Train/Test Split\n",
    "\n",
    "Wir splitten die Daten **stratifiziert**, damit das Verhältnis von 0/1 im Train- und Testset gleich bleibt und die Evaluation fair ist."
   ],
   "id": "6ec447f75abb9f8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T15:40:15.599095400Z",
     "start_time": "2026-01-11T15:40:15.460146700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target = \"Diabetes_binary\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "print(\"Train label distribution:\\n\", y_train.value_counts(normalize=True).round(3))"
   ],
   "id": "f041454a6525b3d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (202944, 28)\n",
      "Test shape: (50736, 28)\n",
      "Train label distribution:\n",
      " Diabetes_binary\n",
      "0    0.842\n",
      "1    0.158\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3) Modell\n",
    "\n",
    "Wir nutzen **Logistic Regression** als robuste, interpretierbare Baseline und setzen `class_weight=\"balanced\"`, um das (immer noch vorhandene) Ungleichgewicht zu berücksichtigen."
   ],
   "id": "8d261adcb60f5e7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T15:41:20.141118900Z",
     "start_time": "2026-01-11T15:40:15.674033300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, f1_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Pipeline (Skalierung + SMOTE inside pipeline to avoid leakage)\n",
    "pipe_logreg = ImbPipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(random_state=42, class_weight=\"balanced\", max_iter=1000, solver=\"lbfgs\",l1_ratio=0.5) )\n",
    "])\n",
    "iters = [4000 + i * (6000 - 4000) // (5 - 1) for i in range(5)]\n",
    "# Parameterraum (stabile, kompatible Kombinationen für LogisticRegression)\n",
    "param_dist = {\n",
    "    \"clf__C\": np.logspace(-4, 2, 50),                 # inverse Regularization\n",
    "    \"clf__solver\": [\"saga\"],\n",
    "    \"clf__tol\": [1e-4, 1e-3, 1e-2],\n",
    "    \"clf__max_iter\": iters\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "rs_log = RandomizedSearchCV(\n",
    "    estimator=pipe_logreg,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=80,\n",
    "    scoring=scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    return_train_score=True,\n",
    "    verbose=1\n",
    "\n",
    ")\n",
    "\n",
    "# Fit (verwendet vorhandene X_train / y_train im Notebook)\n",
    "rs_log.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best CV F1:\", rs_log.best_score_)\n",
    "print(\"Best params:\", rs_log.best_params_)\n"
   ],
   "id": "459660fecdb70750",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "Best CV F1: 0.4702790759399398\n",
      "Best params: {'clf__tol': 0.001, 'clf__solver': 'saga', 'clf__max_iter': 4500, 'clf__C': np.float64(0.0007196856730011522)}\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4) Evaluation\n",
    "\n",
    "Wir betrachten neben dem Report auch die **Confusion Matrix**, weil sie zeigt, ob das Modell Risiko-Fälle übersieht (False Negatives).\n",
    "Zusätzlich nutzen wir **F1 (für Klasse 1)** und **ROC-AUC**, um die Qualität bei ungleichen Klassen besser zu bewerten als nur Accuracy."
   ],
   "id": "44440274d245f984"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T15:41:20.297408700Z",
     "start_time": "2026-01-11T15:41:20.253081400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluation auf Testdaten\n",
    "y_pred = rs_log.predict(X_test)\n",
    "# einige solver liefern nicht immer predict_proba; handle defensiv\n",
    "y_proba = None\n",
    "if hasattr(rs_log.best_estimator_.named_steps[\"clf\"], \"predict_proba\"):\n",
    "    y_proba = rs_log.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Classification Report (LogReg best) ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(f\"F1 (positive class): {f1_score(y_test, y_pred):.4f}\")\n",
    "if y_proba is not None:\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "\n",
    "# Optional: Top CV-Konfigurationen anzeigen\n",
    "res = pd.DataFrame(rs_log.cv_results_)\n",
    "top = res.sort_values(\"mean_test_score\", ascending=False).head(10)[[\n",
    "    \"params\", \"mean_test_score\", \"std_test_score\"\n",
    "]]\n",
    "print(\"Top 10 CV-Konfigurationen:\")\n",
    "print(top.to_string(index=False))"
   ],
   "id": "c931d4f3c8229d2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Report (LogReg best) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.73      0.82     42741\n",
      "           1       0.34      0.76      0.47      7995\n",
      "\n",
      "    accuracy                           0.73     50736\n",
      "   macro avg       0.64      0.74      0.65     50736\n",
      "weighted avg       0.85      0.73      0.76     50736\n",
      "\n",
      "Confusion Matrix:\n",
      "[[31012 11729]\n",
      " [ 1917  6078]]\n",
      "F1 (positive class): 0.4711\n",
      "ROC-AUC: 0.8173\n",
      "Top 10 CV-Konfigurationen:\n",
      "                                                                                              params  mean_test_score  std_test_score\n",
      "  {'clf__tol': 0.001, 'clf__solver': 'saga', 'clf__max_iter': 4500, 'clf__C': 0.0007196856730011522}         0.470279        0.002928\n",
      "  {'clf__tol': 0.001, 'clf__solver': 'saga', 'clf__max_iter': 5000, 'clf__C': 0.0005428675439323859}         0.470094        0.002758\n",
      " {'clf__tol': 0.0001, 'clf__solver': 'saga', 'clf__max_iter': 4000, 'clf__C': 0.0009540954763499944}         0.470083        0.002551\n",
      "  {'clf__tol': 0.001, 'clf__solver': 'saga', 'clf__max_iter': 6000, 'clf__C': 0.0009540954763499944}         0.470079        0.002563\n",
      "{'clf__tol': 0.0001, 'clf__solver': 'saga', 'clf__max_iter': 4500, 'clf__C': 0.00040949150623804275}         0.469855        0.002724\n",
      "{'clf__tol': 0.0001, 'clf__solver': 'saga', 'clf__max_iter': 5000, 'clf__C': 0.00040949150623804275}         0.469855        0.002724\n",
      " {'clf__tol': 0.001, 'clf__solver': 'saga', 'clf__max_iter': 4000, 'clf__C': 0.00040949150623804275}         0.469851        0.002769\n",
      "  {'clf__tol': 0.01, 'clf__solver': 'saga', 'clf__max_iter': 4000, 'clf__C': 0.00040949150623804275}         0.469735        0.002763\n",
      "   {'clf__tol': 0.01, 'clf__solver': 'saga', 'clf__max_iter': 4500, 'clf__C': 0.0016768329368110084}         0.469458        0.002399\n",
      "  {'clf__tol': 0.01, 'clf__solver': 'saga', 'clf__max_iter': 4500, 'clf__C': 0.00030888435964774815}         0.469370        0.002974\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.1) Random Forest als Vergleich",
   "id": "d92ca1084c943c36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:14:57.634195700Z",
     "start_time": "2026-01-11T15:41:20.298917500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# python\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Pipeline mit SMOTE (Vermeidet Data-Leakage durch Einbettung in die Pipeline)\n",
    "pipe_rf_tune = ImbPipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"smote\", SMOTE(sampling_strategy=0.5, random_state=42)),\n",
    "    (\"clf\", RandomForestClassifier(random_state=42, n_jobs=-1, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "# Suchraum (RandomizedSearchCV)\n",
    "param_dist = {\n",
    "    \"clf__n_estimators\": [100, 200, 500, 800],\n",
    "    \"clf__max_depth\": [None, 6, 8, 12, 16],\n",
    "    \"clf__max_features\": [\"sqrt\", \"log2\", 0.2, 0.5],\n",
    "    \"clf__min_samples_split\": [2, 5, 10],\n",
    "    \"clf__min_samples_leaf\": [1, 2, 4],\n",
    "    \"clf__bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "rs_rf = RandomizedSearchCV(\n",
    "    estimator=pipe_rf_tune,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=40,\n",
    "    scoring=scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    return_train_score=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit (führt die Suche durch)\n",
    "rs_rf.fit(X_train, y_train)\n",
    "\n",
    "# Ergebnisse\n",
    "print(\"Best CV F1:\", rs_rf.best_score_)\n",
    "print(\"Best params:\", rs_rf.best_params_)\n",
    "\n",
    "# Speicherung des besten Pipelines\n",
    "out_path = MODEL_OUT.with_suffix(\".rf_best.joblib\")\n",
    "joblib.dump(rs_rf.best_estimator_, out_path)\n",
    "print(\"Bestes RF-Modell gespeichert:\", out_path)\n",
    "\n",
    "# Kurze Evaluation auf Testdaten\n",
    "y_pred_rf = rs_rf.predict(X_test)\n",
    "y_proba_rf = rs_rf.predict_proba(X_test)[:, 1]\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "print(\"=== Classification Report (RF best) ===\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(f\"F1 (positive class): {f1_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba_rf):.4f}\")\n",
    "\n",
    "# Optional: einfache Zusammenfassung der Top-Konfigurationen\n",
    "res = pd.DataFrame(rs_rf.cv_results_)\n",
    "top = res.sort_values(\"mean_test_score\", ascending=False).head(10)[[\n",
    "    \"params\", \"mean_test_score\", \"std_test_score\"\n",
    "]]\n",
    "print(\"Top 10 CV-Konfigurationen:\")\n",
    "print(top.to_string(index=False))\n",
    "\n"
   ],
   "id": "8ca2a31ec85397d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best CV F1: 0.4847691344481865\n",
      "Best params: {'clf__n_estimators': 100, 'clf__min_samples_split': 10, 'clf__min_samples_leaf': 1, 'clf__max_features': 0.5, 'clf__max_depth': 12, 'clf__bootstrap': True}\n",
      "Bestes RF-Modell gespeichert: ..\\models\\diabetes_binary_model.rf_best.joblib\n",
      "=== Classification Report (RF best) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86     42741\n",
      "           1       0.39      0.64      0.48      7995\n",
      "\n",
      "    accuracy                           0.79     50736\n",
      "   macro avg       0.66      0.73      0.67     50736\n",
      "weighted avg       0.84      0.79      0.80     50736\n",
      "\n",
      "Confusion Matrix:\n",
      "[[34715  8026]\n",
      " [ 2878  5117]]\n",
      "F1 (positive class): 0.4842\n",
      "ROC-AUC: 0.8165\n",
      "Top 10 CV-Konfigurationen:\n",
      "                                                                                                                                                          params  mean_test_score  std_test_score\n",
      "    {'clf__n_estimators': 100, 'clf__min_samples_split': 10, 'clf__min_samples_leaf': 1, 'clf__max_features': 0.5, 'clf__max_depth': 12, 'clf__bootstrap': True}         0.484769        0.004998\n",
      "  {'clf__n_estimators': 200, 'clf__min_samples_split': 5, 'clf__min_samples_leaf': 4, 'clf__max_features': 'sqrt', 'clf__max_depth': 16, 'clf__bootstrap': True}         0.484658        0.005090\n",
      " {'clf__n_estimators': 800, 'clf__min_samples_split': 5, 'clf__min_samples_leaf': 1, 'clf__max_features': 'sqrt', 'clf__max_depth': 12, 'clf__bootstrap': False}         0.483932        0.004500\n",
      "  {'clf__n_estimators': 100, 'clf__min_samples_split': 2, 'clf__min_samples_leaf': 4, 'clf__max_features': 'log2', 'clf__max_depth': 16, 'clf__bootstrap': True}         0.483845        0.004604\n",
      "{'clf__n_estimators': 200, 'clf__min_samples_split': 10, 'clf__min_samples_leaf': 1, 'clf__max_features': 'sqrt', 'clf__max_depth': 16, 'clf__bootstrap': False}         0.483674        0.003957\n",
      "   {'clf__n_estimators': 500, 'clf__min_samples_split': 10, 'clf__min_samples_leaf': 2, 'clf__max_features': 0.2, 'clf__max_depth': 16, 'clf__bootstrap': False}         0.483646        0.004525\n",
      "     {'clf__n_estimators': 800, 'clf__min_samples_split': 5, 'clf__min_samples_leaf': 4, 'clf__max_features': 0.2, 'clf__max_depth': 12, 'clf__bootstrap': True}         0.483208        0.004023\n",
      " {'clf__n_estimators': 100, 'clf__min_samples_split': 10, 'clf__min_samples_leaf': 1, 'clf__max_features': 'log2', 'clf__max_depth': 16, 'clf__bootstrap': True}         0.483174        0.004009\n",
      "  {'clf__n_estimators': 200, 'clf__min_samples_split': 2, 'clf__min_samples_leaf': 2, 'clf__max_features': 'sqrt', 'clf__max_depth': 16, 'clf__bootstrap': True}         0.483010        0.005290\n",
      "     {'clf__n_estimators': 500, 'clf__min_samples_split': 5, 'clf__min_samples_leaf': 1, 'clf__max_features': 0.2, 'clf__max_depth': 16, 'clf__bootstrap': True}         0.482718        0.004156\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.2) MLP als Vergleich (mit Hyperparameter-Tuning)",
   "id": "5f551027ec32b080"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:17:46.389662500Z",
     "start_time": "2026-01-11T16:14:57.702727100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import joblib\n",
    "\n",
    "# Pipeline-Basis (verwende dieselben X_train/y_train wie im Notebook)\n",
    "pipe_mlp = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", MLPClassifier(\n",
    "        max_iter=2000,\n",
    "        early_stopping=True,       # nötig, damit validation_scores_ verfügbar ist\n",
    "        n_iter_no_change=25,\n",
    "        tol=1e-4,\n",
    "        random_state=42,\n",
    "        verbose=False\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Suchraum (zufällige Suche)\n",
    "param_dist = {\n",
    "    \"clf__hidden_layer_sizes\": [(32,16), (64,32), (128,64), (64,32,16), (128,64,32)],\n",
    "    \"clf__activation\": [\"relu\", \"tanh\"],\n",
    "    \"clf__alpha\": [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    \"clf__learning_rate_init\": [1e-4, 5e-4, 1e-3, 5e-3],\n",
    "    \"clf__learning_rate\": [\"constant\", \"adaptive\"],\n",
    "    # solver kept as 'adam' (robust für tiefe Netze)\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    pipe_mlp,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=25,\n",
    "    scoring=scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    return_train_score=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit (führt die Suche durch)\n",
    "rs.fit(X_train, y_train)\n",
    "\n",
    "# Ergebnisse kurz anzeigen\n",
    "print(\"Best F1 (cv):\", rs.best_score_)\n",
    "print(\"Best params:\", rs.best_params_)\n"
   ],
   "id": "faddf2ebf7e1e65b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Best F1 (cv): 0.305753115193338\n",
      "Best params: {'clf__learning_rate_init': 0.001, 'clf__learning_rate': 'constant', 'clf__hidden_layer_sizes': (32, 16), 'clf__alpha': 0.0001, 'clf__activation': 'tanh'}\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5) Speichern\n",
    "\n",
    "Wir speichern das trainierte Pipeline-Modell als `.joblib`, damit die Web-App es direkt laden und reproduzierbar Vorhersagen machen kann."
   ],
   "id": "d95aaa8687cf9af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T16:17:46.447823Z",
     "start_time": "2026-01-11T16:17:46.429396500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "joblib.dump(pipe_logreg, MODEL_OUT)\n",
    "print(\"✅ Modell gespeichert:\", MODEL_OUT)"
   ],
   "id": "2bf44ad6dd8054a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modell gespeichert: ..\\models\\diabetes_binary_model.joblib\n"
     ]
    }
   ],
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
